# -*- coding: utf-8 -*-
"""Trabalho_T3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ytAwa4oCBKT-K_QAYubdMkYRaHKTQ1Ip

# **TRABALHO PRÁTICO COM REDES NEURAIS ARTIFICIAIS**
## Disciplina: Inteligência Artificial e Computacional – DEC0014
## Alunos: Alisson e Maurício
Este trabalho explora a aplicação de Redes Neurais Artificiais (RNA) e Random Forest para prever o preço de carros usados.

# Descrição do Dataset: **Carros Usados**

1. **Brand**: A marca do carro
2. **model**: O modelo específico do carro
3. **Year**: Ano de fabricação do carro.  
4. **Age**: Idade do carro em anos.  
5. **kmDriven**: Quilometragem percorrida pelo carro.  
6. **Transmission**: Tipo de transmissão do carro.
7. **Owner**: Informações sobre o proprietário do carro
8. **FuelType**: Tipo de combustível usado pelo carro
9. **PostedDate**: Data em que o carro foi listado para venda.  
10. **AdditionInfo**: Informações adicionais fornecidas pelo anunciante.  
11. **AskPrice**: Preço pedido pelo carro.  

Link: https://www.kaggle.com/datasets/mohitkumar282/used-car-dataset

# **1. Carregamento e análise inicial do dataset**
"""

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

dataset_path = '/content/used_car_dataset.csv'
df = pd.read_csv(dataset_path)

print("Primeiras linhas do dataset:")
print(df.head())
print("\n Tipos de dados do dataset:")
df.dtypes

df.shape

"""# **2. Limpeza e pré-processamento dos dados**

"""

# Função para extrair valores numéricos de strings
def extract_numeric(val):
    if isinstance(val, str):
        found = re.findall(r"[\d.]+", val)
        return float(found[0]) if found else None
    return val

df['kmDriven'] = df['kmDriven'].apply(extract_numeric)
df['AskPrice'] = df['AskPrice'].apply(extract_numeric)
# Remoção de valores nulos
df = df.dropna()

# Seleção de colunas relevantes
feature_cols = ['Year', 'Age', 'kmDriven', 'Transmission', 'Owner', 'FuelType', 'Brand']
X = df[feature_cols]
y = df['AskPrice']
X = pd.get_dummies(X, columns=['Transmission', 'Owner', 'FuelType', 'Brand'], drop_first=True)

"""# **3. Divisão dos dados em treino e teste e normalização**

"""

# Divisão em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalização dos dados numéricos
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# **4. Treinamento e avaliação da Rede Neural Artificial (RNA)**
- **Camadas intermediárias**: 2 camadas com 64 neurônios cada.
- **Camada de saída**: 1 neurônio.
- **Otimizador**: Adam, que inclui momentum adaptativo.
- **Taxa de aprendizado**: 0.001.
- **Número de épocas**: 100, 200, 400, 800 e 1600.
- **Tamanho do lote**: 32.
"""

def train_rna(epochs, X_train, y_train, X_test, y_test):
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        Dense(64, activation='relu'),
        Dense(1)  # Saída
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])

    # Treinamento do modelo
    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=32, verbose=1)

    # Avaliação
    predictions = model.predict(X_test, verbose=0).flatten()
    test_loss = mean_squared_error(y_test, predictions)  # MSE
    test_mae = mean_absolute_error(y_test, predictions)  # MAE
    test_r2 = r2_score(y_test, predictions)  # R^2
    return test_loss, test_mae, test_r2

"""## Treinamento da RNA com 100, 200, 400, 800 e 1600 épocas"""

print("\nTreinando RNA com 100 épocas...")
rna_100 = train_rna(100, X_train_scaled, y_train, X_test_scaled, y_test)

print("\nTreinando RNA com 200 épocas...")
rna_200 = train_rna(200, X_train_scaled, y_train, X_test_scaled, y_test)

print("\nTreinando RNA com 400 épocas...")
rna_400 = train_rna(400, X_train_scaled, y_train, X_test_scaled, y_test)

print("\nTreinando RNA com 800 épocas...")
rna_800 = train_rna(800, X_train_scaled, y_train, X_test_scaled, y_test)

print("\nTreinando RNA com 1600 épocas...")
rna_1600 = train_rna(1600, X_train_scaled, y_train, X_test_scaled, y_test)

"""## Resultados para o treinamento do RNA



"""

rna_mse_100, rna_mae_100, rna_r2_100 = rna_100
rna_mse_200, rna_mae_200, rna_r2_200 = rna_200
rna_mse_400, rna_mae_400, rna_r2_400 = rna_400
rna_mse_800, rna_mae_800, rna_r2_800 = rna_800
rna_mse_1600, rna_mae_1600, rna_r2_1600 = rna_1600

# Exibindo os resultados finais
print("\n=== Resultados Finais RNA ===")
print(f"RNA com 100 épocas: MSE = {rna_mse_100:.2f}, MAE = {rna_mae_100:.2f}, R² = {rna_r2_100:.2f}")
print(f"RNA com 200 épocas: MSE = {rna_mse_200:.2f}, MAE = {rna_mae_200:.2f}, R² = {rna_r2_200:.2f}")
print(f"RNA com 400 épocas: MSE = {rna_mse_400:.2f}, MAE = {rna_mae_400:.2f}, R² = {rna_r2_400:.2f}")
print(f"RNA com 800 épocas: MSE = {rna_mse_800:.2f}, MAE = {rna_mae_800:.2f}, R² = {rna_r2_800:.2f}")
print(f"RNA com 1600 épocas: MSE = {rna_mse_1600:.2f}, MAE = {rna_mae_1600:.2f}, R² = {rna_r2_1600:.2f}")

"""## Gráfico do RNA"""

rna_epochs = [100, 200, 400, 800, 1600]

# Criando o gráfico com dois eixos Y
fig, ax1 = plt.subplots(figsize=(12, 7))

# Eixo Y para MSE
ax1.set_xlabel('Épocas', fontsize=14)
ax1.set_ylabel('MSE', color='blue', fontsize=14)
ax1.plot(rna_epochs, [rna_mse_100, rna_mse_200, rna_mse_400, rna_mse_800, rna_mse_1600],
         marker='o', label='MSE (RNA)', linestyle='-', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')
ax1.set_ylim(110, 160)  # Ajuste da escala para MSE
for x, y in zip(rna_epochs, [rna_mse_100, rna_mse_200, rna_mse_400, rna_mse_800, rna_mse_1600]):
    ax1.text(x, y + 1, f"{y:.2f}", ha='center', fontsize=9)

# Adicionando o segundo eixo Y para MAE e R²
ax2 = ax1.twinx()
ax2.set_ylabel('MAE / R²', color='green', fontsize=14)
ax2.plot(rna_epochs, [rna_mae_100, rna_mae_200, rna_mae_400, rna_mae_800, rna_mae_1600],
         marker='o', label='MAE (RNA)', linestyle='--', color='orange')
ax2.plot(rna_epochs, [rna_r2_100, rna_r2_200, rna_r2_400, rna_r2_800, rna_r2_1600],
         marker='o', label='R² (RNA)', linestyle=':', color='green')
ax2.tick_params(axis='y', labelcolor='green')
ax2.set_ylim(0, 6)  # Ajuste da escala para MAE e R²
for x, y in zip(rna_epochs, [rna_mae_100, rna_mae_200, rna_mae_400, rna_mae_800, rna_mae_1600]):
    ax2.text(x, y + 0.1, f"{y:.2f}", ha='center', fontsize=9)
for x, y in zip(rna_epochs, [rna_r2_100, rna_r2_200, rna_r2_400, rna_r2_800, rna_r2_1600]):
    ax2.text(x, y + 0.02, f"{y:.2f}", ha='center', fontsize=9)

# Títulos e configurações finais
plt.title('Desempenho da RNA com Diferentes Épocas', fontsize=16)
fig.tight_layout()  # Ajusta o layout para evitar sobreposições

# Adicionando a legenda combinada
fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fontsize=12)
plt.grid(True)

# Exibindo o gráfico
plt.show()

"""# **5. Treinamento e avaliação do modelo Random Forest**
- **Número de árvores (n_estimators)**: 100, 200, 400, 800 e 1600.
- **Profundidade máxima**: Determinada automaticamente.

"""

def train_rf(n_estimators, X_train, y_train, X_test, y_test):
    rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42)
    # Treinamento do modelo
    rf.fit(X_train, y_train)
    y_pred_rf = rf.predict(X_test)

    mse = mean_squared_error(y_test, y_pred_rf)
    mae = mean_absolute_error(y_test, y_pred_rf)
    r2 = r2_score(y_test, y_pred_rf)
    return mse, mae, r2

"""## Treinamento do Random Forest com 100, 200, 400, 800 e 1600 árvores"""

print("\nTreinando Random Forest com 100 árvores...")
rf_100 = train_rf(100, X_train, y_train, X_test, y_test)

print("\nTreinando Random Forest com 200 árvores...")
rf_200 = train_rf(200, X_train, y_train, X_test, y_test)

print("\nTreinando Random Forest com 400 árvores...")
rf_400 = train_rf(400, X_train, y_train, X_test, y_test)

print("\nTreinando Random Forest com 800 árvores...")
rf_800 = train_rf(800, X_train, y_train, X_test, y_test)

print("\nTreinando Random Forest com 1600 árvores...")
rf_1600 = train_rf(1600, X_train, y_train, X_test, y_test)

"""## Resultados para o treinamento do Random Forest"""

rf_mse_100, rf_mae_100, rf_r2_100 = rf_100
rf_mse_200, rf_mae_200, rf_r2_200 = rf_200
rf_mse_400, rf_mae_400, rf_r2_400 = rf_400
rf_mse_800, rf_mae_800, rf_r2_800 = rf_800
rf_mse_1600, rf_mae_1600, rf_r2_1600 = rf_1600

# Exibindo os resultados finais
print("\n=== Resultados Finais Random Forest ===")
print(f"Random Forest com 100 árvores: MSE = {rf_mse_100:.2f}, MAE = {rf_mae_100:.2f}, R² = {rf_r2_100:.2f}")
print(f"Random Forest com 200 árvores: MSE = {rf_mse_200:.2f}, MAE = {rf_mae_200:.2f}, R² = {rf_r2_200:.2f}")
print(f"Random Forest com 400 árvores: MSE = {rf_mse_400:.2f}, MAE = {rf_mae_400:.2f}, R² = {rf_r2_400:.2f}")
print(f"Random Forest com 800 árvores: MSE = {rf_mse_800:.2f}, MAE = {rf_mae_800:.2f}, R² = {rf_r2_800:.2f}")
print(f"Random Forest com 1600 árvores: MSE = {rf_mse_1600:.2f}, MAE = {rf_mae_1600:.2f}, R² = {rf_r2_1600:.2f}")

"""## Gráfico do Random Forest"""

rf_trees = [100, 200, 400, 800, 1600]

# Criando o gráfico com dois eixos Y para Random Forest
fig, ax1 = plt.subplots(figsize=(12, 7))

# Eixo Y para MSE
ax1.set_xlabel('Número de Árvores', fontsize=14)
ax1.set_ylabel('MSE', color='purple', fontsize=14)
ax1.plot(rf_trees, [rf_mse_100, rf_mse_200, rf_mse_400, rf_mse_800, rf_mse_1600],
         marker='s', label='MSE (Random Forest)', linestyle='-', color='purple')
ax1.tick_params(axis='y', labelcolor='purple')
ax1.set_ylim(110, 140)  # Ajuste da escala para MSE
for x, y in zip(rf_trees, [rf_mse_100, rf_mse_200, rf_mse_400, rf_mse_800, rf_mse_1600]):
    ax1.text(x, y + 1, f"{y:.2f}", ha='center', fontsize=9)

# Adicionando o segundo eixo Y para MAE e R²
ax2 = ax1.twinx()
ax2.set_ylabel('MAE / R²', color='green', fontsize=14)
ax2.plot(rf_trees, [rf_mae_100, rf_mae_200, rf_mae_400, rf_mae_800, rf_mae_1600],
         marker='s', label='MAE (Random Forest)', linestyle='--', color='red')
ax2.plot(rf_trees, [rf_r2_100, rf_r2_200, rf_r2_400, rf_r2_800, rf_r2_1600],
         marker='s', label='R² (Random Forest)', linestyle=':', color='brown')
ax2.tick_params(axis='y', labelcolor='green')
ax2.set_ylim(0, 6)  # Ajuste da escala para MAE e R²
for x, y in zip(rf_trees, [rf_mae_100, rf_mae_200, rf_mae_400, rf_mae_800, rf_mae_1600]):
    ax2.text(x, y + 0.1, f"{y:.2f}", ha='center', fontsize=9)
for x, y in zip(rf_trees, [rf_r2_100, rf_r2_200, rf_r2_400, rf_r2_800, rf_r2_1600]):
    ax2.text(x, y + 0.02, f"{y:.2f}", ha='center', fontsize=9)

# Títulos e configurações finais
plt.title('Desempenho do Random Forest com Diferentes Quantidades de Árvores', fontsize=16)
fig.tight_layout()  # Ajusta o layout para evitar sobreposições

# Adicionando a legenda combinada
fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fontsize=12)
plt.grid(True)

# Exibindo o gráfico
plt.show()

"""# **6. Comparação entre RNA e Random Forest**"""

# Comparação dos resultados finais entre RNA e Random Forest
print("\n=== Comparação Final entre RNA e Random Forest ===")
print(f"RNA com 100 épocas: MSE = {rna_mse_100:.2f}, MAE = {rna_mae_100:.2f}, R² = {rna_r2_100:.2f}")
print(f"Random Forest com 100 árvores: MSE = {rf_mse_100:.2f}, MAE = {rf_mae_100:.2f}, R² = {rf_r2_100:.2f}")
print("\n=================================================")
print(f"RNA com 200 épocas: MSE = {rna_mse_200:.2f}, MAE = {rna_mae_200:.2f}, R² = {rna_r2_200:.2f}")
print(f"Random Forest com 200 árvores: MSE = {rf_mse_200:.2f}, MAE = {rf_mae_200:.2f}, R² = {rf_r2_200:.2f}")
print("\n=================================================")
print(f"RNA com 400 épocas: MSE = {rna_mse_400:.2f}, MAE = {rna_mae_400:.2f}, R² = {rna_r2_400:.2f}")
print(f"Random Forest com 400 árvores: MSE = {rf_mse_400:.2f}, MAE = {rf_mae_400:.2f}, R² = {rf_r2_400:.2f}")
print("\n=================================================")
print(f"RNA com 800 épocas: MSE = {rna_mse_800:.2f}, MAE = {rna_mae_800:.2f}, R² = {rna_r2_800:.2f}")
print(f"Random Forest com 800 árvores: MSE = {rf_mse_800:.2f}, MAE = {rf_mae_800:.2f}, R² = {rf_r2_800:.2f}")
print("\n=================================================")
print(f"RNA com 1600 épocas: MSE = {rna_mse_1600:.2f}, MAE = {rna_mae_1600:.2f}, R² = {rna_r2_1600:.2f}")
print(f"Random Forest com 1600 árvores: MSE = {rf_mse_1600:.2f}, MAE = {rf_mae_1600:.2f}, R² = {rf_r2_1600:.2f}")

# Criando o gráfico com dois eixos Y para a comparação
fig, ax1 = plt.subplots(figsize=(14, 8))

# Eixo Y para MSE
ax1.set_xlabel('Épocas (RNA) / Árvores (Random Forest)', fontsize=14)
ax1.set_ylabel('MSE', color='blue', fontsize=14)
ax1.plot(rna_epochs, [rna_mse_100, rna_mse_200, rna_mse_400, rna_mse_800, rna_mse_1600],
         marker='o', label='MSE (RNA)', linestyle='-', color='blue')
ax1.plot(rf_trees, [rf_mse_100, rf_mse_200, rf_mse_400, rf_mse_800, rf_mse_1600],
         marker='s', label='MSE (Random Forest)', linestyle='-', color='purple')
ax1.tick_params(axis='y', labelcolor='blue')
ax1.set_ylim(110, 160)  # Ajuste da escala para MSE
for x, y in zip(rna_epochs, [rna_mse_100, rna_mse_200, rna_mse_400, rna_mse_800, rna_mse_1600]):
    ax1.text(x, y + 1, f"{y:.2f}", ha='center', fontsize=9)
for x, y in zip(rf_trees, [rf_mse_100, rf_mse_200, rf_mse_400, rf_mse_800, rf_mse_1600]):
    ax1.text(x, y + 1, f"{y:.2f}", ha='center', fontsize=9)

# Adicionando o segundo eixo Y para MAE e R²
ax2 = ax1.twinx()
ax2.set_ylabel('MAE / R²', color='green', fontsize=14)
ax2.plot(rna_epochs, [rna_mae_100, rna_mae_200, rna_mae_400, rna_mae_800, rna_mae_1600],
         marker='o', label='MAE (RNA)', linestyle='--', color='orange')
ax2.plot(rna_epochs, [rna_r2_100, rna_r2_200, rna_r2_400, rna_r2_800, rna_r2_1600],
         marker='o', label='R² (RNA)', linestyle=':', color='green')
ax2.plot(rf_trees, [rf_mae_100, rf_mae_200, rf_mae_400, rf_mae_800, rf_mae_1600],
         marker='s', label='MAE (Random Forest)', linestyle='--', color='red')
ax2.plot(rf_trees, [rf_r2_100, rf_r2_200, rf_r2_400, rf_r2_800, rf_r2_1600],
         marker='s', label='R² (Random Forest)', linestyle=':', color='brown')
ax2.tick_params(axis='y', labelcolor='green')
ax2.set_ylim(0, 6)  # Ajuste da escala para MAE e R²
for x, y in zip(rna_epochs, [rna_mae_100, rna_mae_200, rna_mae_400, rna_mae_800, rna_mae_1600]):
    ax2.text(x, y + 0.1, f"{y:.2f}", ha='center', fontsize=9)
for x, y in zip(rna_epochs, [rna_r2_100, rna_r2_200, rna_r2_400, rna_r2_800, rna_r2_1600]):
    ax2.text(x, y + 0.02, f"{y:.2f}", ha='center', fontsize=9)
for x, y in zip(rf_trees, [rf_mae_100, rf_mae_200, rf_mae_400, rf_mae_800, rf_mae_1600]):
    ax2.text(x, y + 0.1, f"{y:.2f}", ha='center', fontsize=9)
for x, y in zip(rf_trees, [rf_r2_100, rf_r2_200, rf_r2_400, rf_r2_800, rf_r2_1600]):
    ax2.text(x, y + 0.02, f"{y:.2f}", ha='center', fontsize=9)

# Títulos e configurações finais
plt.title('Comparação entre RNA e Random Forest', fontsize=16)
fig.tight_layout()  # Ajusta o layout para evitar sobreposições

# Adicionando a legenda combinada
fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3, fontsize=12)
plt.grid(True)

# Exibindo o gráfico
plt.show()

"""Os resultados mostram que o Random Forest teve melhor desempenho que a RNA. O MSE do Random Forest se manteve estável em torno de 117, enquanto a RNA aumentou para 157 com mais épocas, indicando overfitting. O MAE do Random Forest foi consistentemente mais baixo (4.38) em comparação com a RNA, que subiu para 5.28. Além disso, o R² do Random Forest (0.41) foi superior, confirmando sua maior eficiência e estabilidade."""